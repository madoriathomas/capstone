{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Headline Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_confusion_matrix \n",
    "import string\n",
    "import re\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                               link          domain  \\\n",
       "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
       "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
       "2  SCIENCE  https://www.express.co.uk/news/science/1322607...   express.co.uk   \n",
       "3  SCIENCE  https://www.ndtv.com/world-news/glaciers-could...        ndtv.com   \n",
       "4  SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...       thesun.ie   \n",
       "\n",
       "        published_date                                              title lang  \n",
       "0  2020-08-06 13:59:45  A closer look at water-splitting's solar fuel ...   en  \n",
       "1  2020-08-12 15:14:19  An irresistible scent makes locusts swarm, stu...   en  \n",
       "2  2020-08-13 21:01:00  Artificial intelligence warning: AI will know ...   en  \n",
       "3  2020-08-03 22:18:26   Glaciers Could Have Sculpted Mars Valleys: Study   en  \n",
       "4  2020-08-12 19:54:36  Perseid meteor shower 2020: What time and how ...   en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('data/labeled_newscatcher_dataset.csv', sep=\";\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus.title\n",
    "y = corpus.topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing a train-test split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=549841, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('vectorize',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid={'mnb__alpha': array([0.  , 0.25, 0.5 , 0.75, 1.  ])})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_mnb = Pipeline(steps=([(\"vectorize\", CountVectorizer(stop_words= sw)), \n",
    "                            (\"mnb\", MultinomialNB())]))\n",
    "\n",
    "parameters = {'mnb__alpha': np.linspace(0, 1.0, 5)}\n",
    "\n",
    "count_gs = GridSearchCV(estimator= count_mnb,\n",
    "                 param_grid= parameters,\n",
    "                 cv=5, error_score= 'raise')\n",
    "\n",
    "count_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the training score: 0.8780108340523033\n",
      "This is the testing score: 0.8008720548448951\n",
      "Best parameters: {'mnb__alpha': 0.25}\n"
     ]
    }
   ],
   "source": [
    "print(f'This is the training score: {count_gs.score(X_train, y_train)}')\n",
    "print(f'This is the testing score: {count_gs.score(X_test, y_test)}')\n",
    "print(f'Best parameters: {count_gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_forest = Pipeline(steps=([(\"vectorize\", CountVectorizer(stop_words= sw)), \n",
    "                                (\"rf\", RandomForestClassifier())]))\n",
    "\n",
    "parameters = {'rf__min_samples_split': [2, 3, 4, 5]}\n",
    "\n",
    "count_rf = GridSearchCV(estimator= count_forest,\n",
    "                 param_grid= parameters,\n",
    "                 cv=5, error_score= 'raise')\n",
    "\n",
    "count_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the training score: 0.5037975757747196\n",
      "This is the testing score: 0.4981744635024034\n",
      "Best parameters: {'rf__max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'This is the training score: {count_rf.score(X_train, y_train)}')\n",
    "print(f'This is the testing score: {count_rf.score(X_test, y_test)}')\n",
    "print(f'Best parameters: {count_rf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('vectorize',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid={'mnb__alpha': array([0.  , 0.25, 0.5 , 0.75, 1.  ])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mnb = Pipeline(steps=([(\"vectorize\", TfidfVectorizer(stop_words= sw)),\n",
    "                            (\"mnb\", MultinomialNB())]))\n",
    "\n",
    "parameters = {'mnb__alpha': np.linspace(0, 1.0, 5)}\n",
    "\n",
    "tfidf_gs = GridSearchCV(estimator= tfidf_mnb,\n",
    "                 param_grid= parameters,\n",
    "                 cv=5, error_score= 'raise')\n",
    "\n",
    "tfidf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the training score: 0.8851675317879015\n",
      "This is the testing score: 0.8019752567571117\n",
      "Best parameters: {'mnb__alpha': 0.25}\n"
     ]
    }
   ],
   "source": [
    "print(f'This is the training score: {tfidf_gs.score(X_train, y_train)}')\n",
    "print(f'This is the testing score: {tfidf_gs.score(X_test, y_test)}')\n",
    "print(f'Best parameters: {tfidf_gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_forest = Pipeline(steps=([(\"vectorize\", TfidfVectorizer(stop_words= sw)), \n",
    "                                (\"rf\", RandomForestClassifier())]))\n",
    "\n",
    "parameters = {'rf__min_samples_split': [2, 3, 4, 5]}\n",
    "\n",
    "tfidf_rf = GridSearchCV(estimator= tfidf_forest,\n",
    "                 param_grid= parameters,\n",
    "                 cv=5, error_score= 'raise')\n",
    "\n",
    "tfidf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'This is the training score: {tfidf_rf.score(X_train, y_train)}')\n",
    "print(f'This is the testing score: {tfidf_rf.score(X_test, y_test)}')\n",
    "print(f'Best parameters: {tfidf_rf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba33acf19d6f8950a82f714c4929bec5c0642f06f1336034ea15f517b72499a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('learn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
